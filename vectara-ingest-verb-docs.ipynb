{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ingest jambonz.org verb docs\n",
    "This notebook parses the source markdown files that appear under https://www.jambonz.org/docs/webhooks and adds them to a Vectara corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import requests\n",
    "import os\n",
    "from getpass import getpass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_id = 730456851 # vectara customer id\n",
    "corpus_id = 3  # vectara corpus id\n",
    "api_key = getpass(\"Enter your Vectara API key: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MarkdownParser:\n",
    "    def parse(self, file_path, customer, corpus_id):\n",
    "        with open(file_path, 'r') as file:\n",
    "            content = file.read()\n",
    "\n",
    "        # Extract H1 header\n",
    "        h1 = re.search(r'^# (.+)', content, re.MULTILINE).group(1)\n",
    "\n",
    "        # Extract the first sentence as the brief description\n",
    "        description = re.search(r'^\\n(.+?)\\.', content, re.MULTILINE | re.DOTALL).group(1).strip() + '.'\n",
    "\n",
    "        # Extract the prelude text (everything after the first sentence until the table starts)\n",
    "        prelude_start = content.find(description) + len(description)\n",
    "        prelude_end = content.find('|', prelude_start)\n",
    "        prelude_text = content[prelude_start:prelude_end].strip()\n",
    "\n",
    "        sections = [\n",
    "            {\n",
    "                \"metadataJson\": json.dumps({\"type\": \"prelude\"}),\n",
    "                \"text\": prelude_text\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        # Extract table of values if present\n",
    "        table_match = re.search(r'^\\| (.+?) \\|\\n\\| (.+?) \\|\\n((?:\\| .+? \\|\\n)+)', content, re.MULTILINE | re.DOTALL)\n",
    "        if table_match:\n",
    "            headers = [header.strip() for header in table_match.group(1).split('|')]\n",
    "            rows = table_match.group(3).split('\\n')\n",
    "            table_data = [\n",
    "                {headers[i].strip(): cell.strip() for i, cell in enumerate(row.split('|')) if i < len(headers)}\n",
    "                for row in rows if row\n",
    "            ]\n",
    "            sections.append({\n",
    "                \"metadataJson\": json.dumps({\"type\": \"verb properties\"}),\n",
    "                \"text\": json.dumps(table_data)\n",
    "            })\n",
    "\n",
    "            # Determine the start of the follow-up text\n",
    "            follow_up_start = content.find('\\n\\n', table_match.end()) + 2\n",
    "        else:\n",
    "            follow_up_start = prelude_end\n",
    "\n",
    "        # Extract follow-up text if present\n",
    "        follow_up_end = re.search(r'\\n<p class=\"flex\">', content, re.MULTILINE | re.DOTALL)\n",
    "        follow_up_end = follow_up_end.start() if follow_up_end else len(content)\n",
    "        follow_up_text = content[follow_up_start:follow_up_end].strip()\n",
    "        if follow_up_text:\n",
    "            sections.append({\n",
    "                \"metadataJson\": json.dumps({\"type\": \"detail\"}),\n",
    "                \"text\": follow_up_text\n",
    "            })\n",
    "\n",
    "        # Format data for Vectara\n",
    "        vectara_data = {\n",
    "            \"documentId\": f\"verb:{h1}\",\n",
    "            \"title\": f\"The jambonz {h1} verb\",\n",
    "            \"description\": description,\n",
    "            \"metadataJson\": json.dumps({\"verb\": h1}),\n",
    "            \"sections\": sections\n",
    "        }\n",
    "\n",
    "        return {\n",
    "            \"customerId\": customer_id,\n",
    "            \"corpusId\": corpus_id,\n",
    "            \"document\": vectara_data\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_to_vectara(data, customer_id, api_key):\n",
    "    url = \"https://api.vectara.io/v1/index\"\n",
    "\n",
    "    headers = {\n",
    "        'Content-Type': 'application/json',\n",
    "        'Accept': 'application/json',\n",
    "        'x-api-key': api_key,\n",
    "        'customer-id': str(customer_id)\n",
    "    }\n",
    "\n",
    "    payload = json.dumps(data)\n",
    "    response = requests.request(\"POST\", url, headers=headers, data=payload)\n",
    "    print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_files(root_folder, file_names, customer_id, corpus_id):\n",
    "    parser = MarkdownParser()\n",
    "    \n",
    "    for file_name in file_names:\n",
    "        print(f\"Processing {file_name}\")\n",
    "        file_path = os.path.join(root_folder, file_name)\n",
    "        data = parser.parse(file_path, customer_id, corpus_id)\n",
    "        upload_to_vectara(data, customer_id, api_key)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing conference.md\n",
      "{\"status\":{\"code\":\"ALREADY_EXISTS\", \"statusDetail\":\"\", \"cause\":null}, \"quotaConsumed\":{\"numChars\":\"81\", \"numMetadataChars\":\"198\"}}\n",
      "Processing hangup.md\n",
      "{\"status\":{\"code\":\"ALREADY_EXISTS\", \"statusDetail\":\"\", \"cause\":null}, \"quotaConsumed\":{\"numChars\":\"87\", \"numMetadataChars\":\"200\"}}\n",
      "Processing leave.md\n",
      "{\"status\":{\"code\":\"ALREADY_EXISTS\", \"statusDetail\":\"\", \"cause\":null}, \"quotaConsumed\":{\"numChars\":\"71\", \"numMetadataChars\":\"183\"}}\n",
      "Processing lex.md\n",
      "{\"status\":{\"code\":\"ALREADY_EXISTS\", \"statusDetail\":\"\", \"cause\":null}, \"quotaConsumed\":{\"numChars\":\"82\", \"numMetadataChars\":\"202\"}}\n",
      "Processing redirect.md\n",
      "{\"status\":{\"code\":\"ALREADY_EXISTS\", \"statusDetail\":\"\", \"cause\":null}, \"quotaConsumed\":{\"numChars\":\"139\", \"numMetadataChars\":\"254\"}}\n",
      "Processing tag.md\n",
      "{\"status\":{\"code\":\"ALREADY_EXISTS\", \"statusDetail\":\"\", \"cause\":null}, \"quotaConsumed\":{\"numChars\":\"162\", \"numMetadataChars\":\"272\"}}\n",
      "Processing queue-notifications.md\n",
      "{\"status\":{\"code\":\"ALREADY_EXISTS\", \"statusDetail\":\"\", \"cause\":null}, \"quotaConsumed\":{\"numChars\":\"136\", \"numMetadataChars\":\"278\"}}\n",
      "Processing dialogflow.md\n",
      "{\"status\":{\"code\":\"ALREADY_EXISTS\", \"statusDetail\":\"\", \"cause\":null}, \"quotaConsumed\":{\"numChars\":\"193\", \"numMetadataChars\":\"344\"}}\n",
      "Processing dtmf.md\n",
      "{\"status\":{\"code\":\"ALREADY_EXISTS\", \"statusDetail\":\"\", \"cause\":null}, \"quotaConsumed\":{\"numChars\":\"78\", \"numMetadataChars\":\"189\"}}\n",
      "Processing message.md\n",
      "{\"status\":{\"code\":\"ALREADY_EXISTS\", \"statusDetail\":\"\", \"cause\":null}, \"quotaConsumed\":{\"numChars\":\"65\", \"numMetadataChars\":\"184\"}}\n",
      "Processing pause.md\n",
      "{\"status\":{\"code\":\"ALREADY_EXISTS\", \"statusDetail\":\"\", \"cause\":null}, \"quotaConsumed\":{\"numChars\":\"89\", \"numMetadataChars\":\"201\"}}\n",
      "Processing play.md\n",
      "{\"status\":{\"code\":\"ALREADY_EXISTS\", \"statusDetail\":\"\", \"cause\":null}, \"quotaConsumed\":{\"numChars\":\"81\", \"numMetadataChars\":\"192\"}}\n",
      "Processing rasa.md\n",
      "{\"status\":{\"code\":\"ALREADY_EXISTS\", \"statusDetail\":\"\", \"cause\":null}, \"quotaConsumed\":{\"numChars\":\"78\", \"numMetadataChars\":\"199\"}}\n",
      "Processing sip-decline.md\n",
      "{\"status\":{\"code\":\"ALREADY_EXISTS\", \"statusDetail\":\"\", \"cause\":null}, \"quotaConsumed\":{\"numChars\":\"178\", \"numMetadataChars\":\"296\"}}\n",
      "Processing sip-refer.md\n",
      "{\"status\":{\"code\":\"ALREADY_EXISTS\", \"statusDetail\":\"\", \"cause\":null}, \"quotaConsumed\":{\"numChars\":\"80\", \"numMetadataChars\":\"196\"}}\n",
      "Processing sip-request.md\n",
      "{\"status\":{\"code\":\"ALREADY_EXISTS\", \"statusDetail\":\"\", \"cause\":null}, \"quotaConsumed\":{\"numChars\":\"136\", \"numMetadataChars\":\"254\"}}\n",
      "Processing gather.md\n",
      "{\"status\":{\"code\":\"ALREADY_EXISTS\", \"statusDetail\":\"\", \"cause\":null}, \"quotaConsumed\":{\"numChars\":\"84\", \"numMetadataChars\":\"197\"}}\n",
      "Processing transcribe.md\n",
      "{\"status\":{\"code\":\"ALREADY_EXISTS\", \"statusDetail\":\"\", \"cause\":null}, \"quotaConsumed\":{\"numChars\":\"116\", \"numMetadataChars\":\"233\"}}\n",
      "Processing say.md\n",
      "{\"status\":{\"code\":\"ALREADY_EXISTS\", \"statusDetail\":\"\", \"cause\":null}, \"quotaConsumed\":{\"numChars\":\"91\", \"numMetadataChars\":\"201\"}}\n",
      "Processing listen.md\n",
      "{\"status\":{\"code\":\"ALREADY_EXISTS\", \"statusDetail\":\"\", \"cause\":null}, \"quotaConsumed\":{\"numChars\":\"61\", \"numMetadataChars\":\"184\"}}\n",
      "Processing dequeue.md\n",
      "{\"status\":{\"code\":\"ALREADY_EXISTS\", \"statusDetail\":\"\", \"cause\":null}, \"quotaConsumed\":{\"numChars\":\"51\", \"numMetadataChars\":\"165\"}}\n",
      "Processing enqueue.md\n",
      "{\"status\":{\"code\":\"ALREADY_EXISTS\", \"statusDetail\":\"\", \"cause\":null}, \"quotaConsumed\":{\"numChars\":\"344\", \"numMetadataChars\":\"492\"}}\n",
      "Processing overview.md\n",
      "{\"status\":{\"code\":\"ALREADY_EXISTS\", \"statusDetail\":\"\", \"cause\":null}, \"quotaConsumed\":{\"numChars\":\"98\", \"numMetadataChars\":\"226\"}}\n",
      "Processing dial.md\n",
      "{\"status\":{\"code\":\"ALREADY_EXISTS\", \"statusDetail\":\"\", \"cause\":null}, \"quotaConsumed\":{\"numChars\":\"164\", \"numMetadataChars\":\"275\"}}\n",
      "Processing recognizer.md\n",
      "{\"status\":{\"code\":\"OK\", \"statusDetail\":\"\", \"cause\":null}, \"quotaConsumed\":{\"numChars\":\"183\", \"numMetadataChars\":\"300\"}}\n",
      "Processing config.md\n",
      "{\"status\":{\"code\":\"OK\", \"statusDetail\":\"\", \"cause\":null}, \"quotaConsumed\":{\"numChars\":\"209\", \"numMetadataChars\":\"322\"}}\n"
     ]
    }
   ],
   "source": [
    "parser = MarkdownParser()\n",
    "root_folder = '/Users/dhorton/beachdog-enterprises/beachdog-networks/git/jambones.org/git/hosted-cpaas/next-static-site/markdown/docs/webhooks'\n",
    "file_names = [\n",
    "  'conference.md',\n",
    "  'hangup.md',\n",
    "  'leave.md',\n",
    "  'lex.md',\n",
    "  'redirect.md',\n",
    "  'tag.md',\n",
    "  'queue-notifications.md',\n",
    "  'dialogflow.md',\n",
    "  'dtmf.md',\n",
    "  'message.md',\n",
    "  'pause.md',\n",
    "  'play.md',\n",
    "  'rasa.md',\n",
    "  'sip-decline.md',\n",
    "  'sip-refer.md',\n",
    "  'sip-request.md',\n",
    "  'gather.md',\n",
    "  'transcribe.md',\n",
    "  'say.md',\n",
    "  'listen.md',\n",
    "  'dequeue.md',\n",
    "  'enqueue.md',\n",
    "  'overview.md',\n",
    "  'dial.md',\n",
    "  'recognizer.md',\n",
    "  'config.md'\n",
    "]\n",
    "process_files(root_folder, file_names, customer_id, corpus_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
